{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1**"
      ],
      "metadata": {
        "id": "bkP_E9fsycMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Student Name:** **Katusabe Victoria**"
      ],
      "metadata": {
        "id": "dJ70agOpyoKM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zrJgU6Z9m8s",
        "outputId": "bd714acb-75e5-4cb3-ddbe-2c5d53c8f9f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas<2.0.0 in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install \"pandas<2.0.0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install joblib\n",
        "!pip install joblib pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWM2_bRpocFO",
        "outputId": "334e9339-9ccb-46c9-e52a-2ed4617d8078"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.ticker as mticks\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "SEED = 321\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "r-X49Soywzjj"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new folder to week 13 file structure\n",
        "import os\n",
        "os.makedirs('/content/drive/MyDrive/Colab data uploads/Data Viz Belt Exam - OptionB/',exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "tYaNOKrGokF6"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm created folder\n",
        "os.listdir('/content/drive/MyDrive/Colab data uploads/Data Viz Belt Exam - OptionB/')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1wbGeXYphUr",
        "outputId": "e992ba4d-6e24-4cbe-a678-71803a743021"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data Dictionary.html',\n",
              " 'saved_model.joblib',\n",
              " 'zillow_home_values-zipcode.csv',\n",
              " 'Data',\n",
              " '.ipynb_checkpoints',\n",
              " 'Autompg']"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Autompg subfolder to Models\n",
        "os.makedirs('/content/drive/MyDrive/Colab data uploads/Data Viz Belt Exam - OptionB/Autompg',exist_ok=True)\n",
        "# Confirm created folder\n",
        "os.listdir('/content/drive/MyDrive/Colab data uploads/Data Viz Belt Exam - OptionB/Autompg')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEQnmuo2qfH6",
        "outputId": "68c967f7-ff48-4afa-cbdd-20599c313293"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import joblib\n",
        "\n",
        "# Load the saved_model.joblib file from Google Drive\n",
        "file_path = '/content/drive/MyDrive/Colab data uploads/Data Viz Belt Exam - OptionB/saved_model.joblib'\n",
        "data = joblib.load(file_path)\n",
        "data"
      ],
      "metadata": {
        "id": "l0GhyTo7BLEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46fce2e6-7a29-45b6-dabe-be432a2162b5"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X_train':       Lot Area  Lot Frontage  Overall Cond  Total Bsmt SF Central Air  \\\n",
              " 853      16269           NaN             5         907.00           Y   \n",
              " 1055     13891        107.00             5       1,710.00           Y   \n",
              " 2483      8900           NaN             4       1,056.00           Y   \n",
              " 2351     11475         85.00             6         713.00           Y   \n",
              " 1700     13654        118.00             5       1,704.00           Y   \n",
              " ...        ...           ...           ...            ...         ...   \n",
              " 1425     11778         91.00             5       2,271.00           Y   \n",
              " 1833     10678         85.00             5       1,683.00           Y   \n",
              " 2847     10890         60.00             5       1,058.00           Y   \n",
              " 124       8800         80.00             7         936.00           Y   \n",
              " 2586      7700         55.00             7         301.00           Y   \n",
              " \n",
              "       Gr Liv Area  TotRms AbvGrd Street  \n",
              " 853           907              5   Pave  \n",
              " 1055         1710              6   Pave  \n",
              " 2483         1056              5   Pave  \n",
              " 2351         1552              6   Pave  \n",
              " 1700         2758              9   Pave  \n",
              " ...           ...            ...    ...  \n",
              " 1425         2276              7   Pave  \n",
              " 1833         2872              9   Pave  \n",
              " 2847         1551              6   Pave  \n",
              " 124          1054              6   Pave  \n",
              " 2586         1145              6   Pave  \n",
              " \n",
              " [2197 rows x 8 columns],\n",
              " 'y_train': 853     140000\n",
              " 1055    372402\n",
              " 2483    107000\n",
              " 2351    179900\n",
              " 1700    418000\n",
              "          ...  \n",
              " 1425    475000\n",
              " 1833    285000\n",
              " 2847    137000\n",
              " 124     137500\n",
              " 2586    127000\n",
              " Name: SalePrice, Length: 2197, dtype: int64,\n",
              " 'X_test':       Lot Area  Lot Frontage  Overall Cond  Total Bsmt SF Central Air  \\\n",
              " 343      13860         75.00             7       1,952.00           Y   \n",
              " 1413      8405         50.00             8         861.00           Y   \n",
              " 2583     11310         75.00             5       1,367.00           Y   \n",
              " 2020      6180         60.00             5         960.00           N   \n",
              " 348       8530           NaN             5         384.00           Y   \n",
              " ...        ...           ...           ...            ...         ...   \n",
              " 2223     25485           NaN             4       1,560.00           Y   \n",
              " 1922     11988         90.00             6       1,244.00           Y   \n",
              " 1497     47007        123.00             7           0.00           Y   \n",
              " 656      10800         60.00             7         676.00           Y   \n",
              " 1404      5190         50.00             5         570.00           Y   \n",
              " \n",
              "       Gr Liv Area  TotRms AbvGrd Street  \n",
              " 343          2704              9   Pave  \n",
              " 1413         1367              7   Pave  \n",
              " 2583         1375              5   Pave  \n",
              " 2020          986              5   Pave  \n",
              " 348          1474              7   Pave  \n",
              " ...           ...            ...    ...  \n",
              " 2223         1560              6   Pave  \n",
              " 1922         1244              6   Pave  \n",
              " 1497         3820             11   Pave  \n",
              " 656          1352              7   Pave  \n",
              " 1404         1079              5   Pave  \n",
              " \n",
              " [733 rows x 8 columns],\n",
              " 'y_test': 343     345000\n",
              " 1413    119000\n",
              " 2583    140000\n",
              " 2020    102000\n",
              " 348     168500\n",
              "          ...  \n",
              " 2223    201000\n",
              " 1922    150000\n",
              " 1497    284700\n",
              " 656     149000\n",
              " 1404    125600\n",
              " Name: SalePrice, Length: 733, dtype: int64,\n",
              " 'preprocessor': ColumnTransformer(transformers=[('pipeline-1',\n",
              "                                  Pipeline(steps=[('simpleimputer',\n",
              "                                                   SimpleImputer())]),\n",
              "                                  <sklearn.compose._column_transformer.make_column_selector object at 0x787f689aa800>),\n",
              "                                 ('pipeline-2',\n",
              "                                  Pipeline(steps=[('simpleimputer',\n",
              "                                                   SimpleImputer(fill_value='MISSING',\n",
              "                                                                 strategy='constant')),\n",
              "                                                  ('onehotencoder',\n",
              "                                                   OneHotEncoder(drop='if_binary',\n",
              "                                                                 sparse=False))]),\n",
              "                                  <sklearn.compose._column_transformer.make_column_selector object at 0x787f689a9db0>)],\n",
              "                   verbose_feature_names_out=False),\n",
              " 'RandomForestRegressor': RandomForestRegressor()}"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the keys of the dictionary stored in the joblib file\n",
        "print(data.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBQHEuMQTB6I",
        "outputId": "7128b861-2fa1-4d47-a550-cfe3570f69b1"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['X_train', 'y_train', 'X_test', 'y_test', 'preprocessor', 'RandomForestRegressor'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of elements in the loaded model\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ9tq5iXVBac",
        "outputId": "fcab6c60-9782-4646-f6d8-e948b52f741d"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data and objects as separate variables\n",
        "X_train = data['X_train']\n",
        "y_train = data['y_train']\n",
        "X_test = data['X_test']\n",
        "y_test = data['y_test']\n",
        "preprocessor = data['preprocessor']\n",
        "#LinearRegression = data['LinearRegression']\n",
        "RandomForestRegressor = data['RandomForestRegressor']"
      ],
      "metadata": {
        "id": "OxOj1NYxsmaC"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving variables.\n",
        "import joblib\n",
        "# creating a dictionary of all of the variables\n",
        "export = {'X_train':X_train,\n",
        "         'y_train': y_train,\n",
        "         'X_test':X_test,\n",
        "          \"y_test\": y_test,\n",
        "         'preprocessor':preprocessor,\n",
        "         'RandomForestRegressor':RandomForestRegressor}\n"
      ],
      "metadata": {
        "id": "d9LUoziSsyJY"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the export dict as a joblib file--saving to new Models/Autompg folder\n",
        "joblib.dump(export, '/content/drive/MyDrive/Colab data uploads/Data Viz Belt Exam - OptionB/saved_model.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj9-tRnNs-DF",
        "outputId": "a73ce2cf-f38c-4a78-e7e9-0dbbf1c37ce6"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab data uploads/Data Viz Belt Exam - OptionB/saved_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm the file was saved by loading it back in\n",
        "loaded = joblib.load('/content/drive/MyDrive/Colab data uploads/Data Viz Belt Exam - OptionB/saved_model.joblib')\n",
        "loaded.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9jHa4uCjDIO",
        "outputId": "8333bdd2-9dd7-433f-8023-960278a06122"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['X_train', 'y_train', 'X_test', 'y_test', 'preprocessor', 'RandomForestRegressor'])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data and objects\n",
        "X_train = loaded['X_train']\n",
        "y_train = loaded['y_train']\n",
        "X_test = loaded['X_test']\n",
        "y_test = loaded['y_test']\n",
        "preprocessor = loaded['preprocessor']\n",
        "RandomForestRegressor = loaded['RandomForestRegressor']"
      ],
      "metadata": {
        "id": "-h3M-zdHixMv"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_processed = preprocessor.transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "X_train_processed\n",
        "X_test_processed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "RsDhpAYcdR8P",
        "outputId": "c0aa0aaf-292c-47a9-c4cf-514f2c4b30c7"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'Y'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-197c08d9484f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train_processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test_processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m         Xs = self._fit_transform(\n\u001b[0m\u001b[1;32m    801\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    656\u001b[0m         )\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    659\u001b[0m                 delayed(func)(\n\u001b[1;32m    660\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;31m# if we have a weight for this transformer, multiply output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    340\u001b[0m                     )\n\u001b[1;32m    341\u001b[0m                 )\n\u001b[0;32m--> 342\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mnew_ve\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'Y'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns = preprocessor.get_feature_names_out()\n",
        "X_test.columns = preprocessor.get_feature_names_out()\n",
        "X_train\n",
        "X_test"
      ],
      "metadata": {
        "id": "N1hEoDPgtzHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the coefficients and save them as a Series with the correct feature names as the index.\n",
        "LinearRegression.coef_"
      ],
      "metadata": {
        "id": "URDRMLwAWFVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "coefficients = [1.10428754e-01, 8.79663271e+01, 1.41612957e+01, 6.07389601e+01, 1.03864442e+02, -7.38974003e+03, 3.42004104e+04, -3.04921243e+04]\n",
        "\n",
        "# Create a Series with coefficients\n",
        "coefficients_series = pd.Series(coefficients)\n",
        "\n",
        "# Print or use the coefficients Series\n",
        "print(coefficients_series)"
      ],
      "metadata": {
        "id": "S2HTqUzYb8oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the pandas option for float format to display the coefficients with pandas in a readable comma separator for thousands and 2 decimal places.\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "coefficients_series"
      ],
      "metadata": {
        "id": "fRDIMqAYuBvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract and create a bar graph of the feature importances, sorted from largest to smallest.\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sorted_feature_importances = RandomForestRegressor.feature_importances_\n",
        "sorted_feature_names = X_train.columns\n",
        "\n",
        "# Sort the feature importances and feature names together\n",
        "sorted_indices = np.argsort(sorted_feature_importances)[::-1]\n",
        "sorted_feature_importances = sorted_feature_importances[sorted_indices]"
      ],
      "metadata": {
        "id": "an3Rq46tdLT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sort the coefficeints by magnitude\n",
        "sorted_feature_importances = np.abs(sorted_feature_importances)\n",
        "# Create a bar graph\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.bar(sorted_feature_names, sorted_feature_importances, color='skyblue')\n",
        "plt.xlabel('Features')\n",
        "# Changed the ylabel variable name to avoid conflict\n",
        "plt.ylabel('Feature Importances (Sorted)')\n",
        "plt.title('Feature Importances (Sorted)')\n",
        "plt.xticks(rotation=70)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d-_GQ9HsuLJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the top 4 most important features?"
      ],
      "metadata": {
        "id": "yvfkUTSAuqNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_4_features = sorted_feature_names[:4]\n",
        "top_4_features"
      ],
      "metadata": {
        "id": "0xn-59gjuR5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Of the top 4 most important features, identify which of these features also appeared in the 4 largest positive or 2 largest negative coefficients.**"
      ],
      "metadata": {
        "id": "cs02i1WauaHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "four_largest = coefficients_series.nlargest(4)\n",
        "four_largest"
      ],
      "metadata": {
        "id": "aDXlmbpYuXLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "btqdDXq4uygS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap"
      ],
      "metadata": {
        "id": "ZDxU3ZNLu4Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply Shap to Explain the Random Forest Model\n",
        "shap_values = shap.TreeExplainer(RandomForestRegressor).shap_values(X_train_processed)\n",
        "shap_values"
      ],
      "metadata": {
        "id": "DVhdE1zMu8GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample 500 rows of the processed X_train data as X_shap, using random_state=321"
      ],
      "metadata": {
        "id": "YKMVzSy6vIpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_shap = X_train_processed[:500]\n",
        "X_shap"
      ],
      "metadata": {
        "id": "6017mQdCvDki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the corresponding y_train values as y_shap"
      ],
      "metadata": {
        "id": "hrgcBTZ7vaUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_shap = y_train[:500]\n",
        "y_shap"
      ],
      "metadata": {
        "id": "FT6PDmcZvV_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a shap model explainer for the random forest model"
      ],
      "metadata": {
        "id": "nDi_AL0YvhkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap_explainer = shap.TreeExplainer(RandomForestRegressor)\n",
        "shap_values = shap_explainer.shap_values(X_shap)\n",
        "shap_values"
      ],
      "metadata": {
        "id": "xOzVV-xDveyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the shap values for the sampled data"
      ],
      "metadata": {
        "id": "AoJ-LJVgvn7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = shap_explainer.shap_values(X_shap)\n",
        "shap_values"
      ],
      "metadata": {
        "id": "OGayHrTHvldC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a summary plot (plot_type=’dot’) of the most important features, according to shap."
      ],
      "metadata": {
        "id": "Z_C_Lb9rv5KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, X_shap, plot_type='dot')"
      ],
      "metadata": {
        "id": "c1oYLgAfvsTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2**\n",
        "\n",
        "Load the provided csv, located in the zip file you downloaded in Part 1."
      ],
      "metadata": {
        "id": "2Zr0UJDHJdIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IFn9u88HDaX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load the saved_model.joblib file from Google Drive\n",
        "file_path = '/content/drive/MyDrive/Colab data uploads/Data Viz Belt Exam - OptionB/zillow_home_values-zipcode.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "uQqO8a5KIfiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "77E4YK2cCexG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "Jd0Bt2xTVdwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt columns containing '20' in their names\n",
        "melted_df = pd.melt(df, id_vars=['RegionID','SizeRank','RegionName','StateName'],\n",
        "                    value_vars=[col for col in df.columns if '20' in col],\n",
        "                    var_name='Date', value_name='Value')\n",
        "\n",
        "# Display the melted DataFrame\n",
        "print(melted_df)"
      ],
      "metadata": {
        "id": "ghqv0l0r5WHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melted_df.head()"
      ],
      "metadata": {
        "id": "VqSSJK9cJDAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melted_df.dtypes"
      ],
      "metadata": {
        "id": "DCWv8yxvKAjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the strings to datetime objects\n",
        "melted_df['Date'] = pd.to_datetime(melted_df['Date'], format='%d%m%Y')\n",
        "melted_df.head()"
      ],
      "metadata": {
        "id": "s2XYoc9xKLd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melted_df.dtypes"
      ],
      "metadata": {
        "id": "o-wfczWVL8BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melted_df = melted_df.set_index('Date')\n",
        "melted_df.head()"
      ],
      "metadata": {
        "id": "ZD1IxtHGMG6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filter specific states from the statename\n",
        "melted_df = melted_df[melted_df['StateName'].isin(['MA', 'PA', 'NY', 'NJ', 'MD'])]\n",
        "melted_df.head()"
      ],
      "metadata": {
        "id": "vIUSCBWJMb_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to keep only rows between 2008 and 2018 inclusive\n",
        "melted_df = melted_df[\"2008\":\"2018\"]\n",
        "\n",
        "# Print the filtered DataFrame\n",
        "melted_df.head()"
      ],
      "metadata": {
        "id": "U-FSSozuNQf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melted_df.tail()"
      ],
      "metadata": {
        "id": "Kk8XL5W9Nd3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample to yearly frequency using mean as the aggregation function\n",
        "yearly_mean_home_values = melted_df.groupby('StateName').resample('Y').mean()\n",
        "\n",
        "yearly_mean_home_values"
      ],
      "metadata": {
        "id": "4o7_-LuwQxPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "W6bvkxZ-RT66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample to yearly frequency using mean as the aggregation function\n",
        "yearly_mean_home_values = melted_df.groupby(['StateName', pd.Grouper(freq='Y')]).mean().unstack(level=0)\n",
        "\n",
        "# Plotting\n",
        "yearly_mean_home_values.plot(kind='line', figsize=(10, 6))\n",
        "\n",
        "plt.title('Yearly Mean Home Values by State')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Mean Home Value')\n",
        "plt.grid(True)\n",
        "plt.legend(title='State')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0opM44b6TdPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt columns containing '20' in their names\n",
        "melted_df2 = pd.melt(df, id_vars=['RegionID','SizeRank','RegionName','StateName','State','City','Metro','CountyName'],\n",
        "                    value_vars=[col for col in df.columns if '20' in col],\n",
        "                    var_name='Date', value_name='Value')\n",
        "\n",
        "# Display the melted DataFrame\n",
        "print(melted_df2)"
      ],
      "metadata": {
        "id": "nzIlXgNB1j86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the strings to datetime objects\n",
        "melted_df2['Date'] = pd.to_datetime(melted_df2['Date'], format='%d%m%Y')\n",
        "melted_df2.head()"
      ],
      "metadata": {
        "id": "ibHSrcDj45BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melted_df2.head()"
      ],
      "metadata": {
        "id": "o_l2Cygk3vFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path\n",
        "file_path = \"/content/drive/MyDrive/Colab data uploads/Data Viz Belt Exam - OptionB/Data/data-for-tableau.csv\"\n",
        "#/content/drive/MyDrive/Colab data uploads/Data Viz Belt Exam - OptionB\n",
        "# Save the DataFrame as a CSV file\n",
        "melted_df2.to_csv(file_path, index=False)\n",
        "\n",
        "print(\"DataFrame saved as CSV file:\", file_path)"
      ],
      "metadata": {
        "id": "25UgvLpyOMoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3**"
      ],
      "metadata": {
        "id": "q5EvAKQE9b8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://public.tableau.com/app/profile/victoria.katusabe/viz/BeltExamPart3KatusabeVictoria/Createachoroplethmapofthemedianhomevaluebyzipcode?publish=yes"
      ],
      "metadata": {
        "id": "zqyW9Sxt9gkh"
      }
    }
  ]
}